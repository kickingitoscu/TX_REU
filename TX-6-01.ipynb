{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named request",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mImportError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-53b109771b00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshapefile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#from urllib2 import urlopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named request"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "import shapefile\n",
    "#from urllib2 import urlopen\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "from functools import partial\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, LineString, Polygon, shape \n",
    "from multiprocessing import Pool\n",
    "import shapely.speedups\n",
    "import geopandas\n",
    "import geopy\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "import plotly_express as px\n",
    "import datetime\n",
    "import plotly.graph_objects as go\n",
    "import mplleaflet\n",
    "from zipfile import ZipFile\n",
    "from io import StringIO, BytesIO\n",
    "from osgeo import osr\n",
    "#import osr\n",
    "sns.set()\n",
    "shapely.speedups.enable()\n",
    "#from census_mapper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home1/07470/mduarte/Notebooks/ATX/06/01.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                  0\n",
       "advertiser_id               0\n",
       "platform                    0\n",
       "location_at                 0\n",
       "latitude                    0\n",
       "longitude                   0\n",
       "altitude                   27\n",
       "horizontal_accuracy         0\n",
       "vertical_accuracy          27\n",
       "heading                237924\n",
       "speed                      99\n",
       "ipv_4                   11616\n",
       "ipv_6                  294133\n",
       "final_country               0\n",
       "user_agent                391\n",
       "background             242578\n",
       "publisher_id                0\n",
       "wifi_ssid              298739\n",
       "wifi_bssid             311115\n",
       "tech_signals           785791\n",
       "carrier                267037\n",
       "device_model              595\n",
       "venue_name             617021\n",
       "venue_category         617028\n",
       "dwell_time             687727\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Unnamed: 0', 'tech_signals', 'speed', 'ipv_4', 'ipv_6', 'wifi_ssid', 'wifi_bssid'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['venue_name', 'venue_category','dwell_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zip_shp_to_gdf(zip_file_name):\n",
    "    \"\"\"\n",
    "    Returns a GeoDataFrame from a URL for a zipped Shapefile\n",
    "    \"\"\"\n",
    "    #print(type(zip_file_name))\n",
    "    #StringIO\n",
    "    zipfile = ZipFile(BytesIO(urlopen(zip_file_name).read()))\n",
    "    filenames = [y for y in sorted(zipfile.namelist()) for ending in ['dbf', 'prj', 'shp', 'shx']\\\n",
    "                 if y.endswith(ending)] \n",
    "    dbf, prj, shp, shx = [BytesIO(zipfile.read(filename)) for filename in filenames]\n",
    "    r = shapefile.Reader(shp=shp, shx=shx, dbf=dbf)\n",
    "    \n",
    "    attributes, geometry = [], []\n",
    "    field_names = [field[0] for field in r.fields[1:]]  \n",
    "    for row in r.shapeRecords():  \n",
    "        geometry.append(shape(row.shape.__geo_interface__))  \n",
    "        attributes.append(dict(zip(field_names, row.record)))  \n",
    "        \n",
    "    proj4_string = osr.SpatialReference(prj.read()).ExportToProj4()\n",
    "    gdf = gpd.GeoDataFrame(data = attributes, geometry = geometry, crs = proj4_string)\n",
    "    return gdf\n",
    "\n",
    "def get_census_variables(year, dataset, geography, area, variables, variable_labels = None):\n",
    "    \"\"\"Wraps the Census API and returns a DataFrame of Census Data\n",
    "    Parameters\n",
    "    ----------\n",
    "    year : integer\n",
    "        Year representing the dataset vintage \n",
    "    dataset : string\n",
    "        the name of the dataset (https://api.census.gov/data.html)\n",
    "    geography : string\n",
    "        the census geography\n",
    "    area : dictionary\n",
    "        dictionary contains the FIPS codes at each nested geographic level. For example \"{'county':'001', 'state':'06'}\"\n",
    "    variables : list\n",
    "        list of the variables to be extracted\n",
    "    variable_labels : list\n",
    "        optional to relabel the variable names. Must be same length as \"variables\"\n",
    "    \"\"\"\n",
    "    \n",
    "    base_url = 'https://api.census.gov/data/{}/{}'.format(year, dataset)\n",
    "    \n",
    "    #define parameters\n",
    "    get_parameter = ','.join(['NAME'] + variables)\n",
    "    for_parameter = '{}:*'.format(geography)\n",
    "    in_paramater = '+'.join([k+':'+v for (k,v) in area.items()])\n",
    "\n",
    "    parameters = {'get' : get_parameter, \n",
    "                  'for' : for_parameter,\n",
    "                  'in' : in_paramater}\n",
    "    \n",
    "    #make request specifiying url and parameters\n",
    "    r = requests.get(base_url, params=parameters)\n",
    "    \n",
    "    #read json into pandas dataframe, specifying first row as column names\n",
    "    data = r.json()\n",
    "    df=pd.DataFrame(columns = data[0], data = data[1:])\n",
    "    \n",
    "    #identify geography fields - concatenate them into a fips code to be set as index and then delete them\n",
    "    geo_fields = [x for x in df.columns if x not in ['NAME'] + variables]\n",
    "    df.index = df[geo_fields].apply(lambda row: ''.join(map(str, row)), 1)\n",
    "    df.index.name = 'FIPS'\n",
    "    df = df.drop(geo_fields, 1)\n",
    "    \n",
    "    if variable_labels:\n",
    "        df = df.rename(columns = dict(zip(variables, variable_labels)))\n",
    "    \n",
    "    #convert data numeric \n",
    "    df = df.applymap(lambda x:pd.to_numeric(x, errors='ignore'))\n",
    "    return df\n",
    "\n",
    "\n",
    "def gen_count_dot_density_map(county, pts_per_person = 300, \n",
    "                              epsg = 2163, seed=10,\n",
    "                              dot_transparency=0.4, figsize=(12,12), \n",
    "                              ax=None, legend=True):\n",
    "    \"\"\"\n",
    "    Wraps previous functions and generates population dot density maps for a specified county by race\n",
    "    \n",
    "    \"\"\"\n",
    "    #read in fips to county name relationship file\n",
    "    fips = pd.read_csv('https://www2.census.gov/geo/docs/reference/codes/files/national_county.txt',\n",
    "                   header=None, dtype={1:np.object, 2:np.object})\n",
    "    fips['name']=fips[3]+', '+fips[0]\n",
    "    fips['fips']=fips[1]+fips[2]\n",
    "    \n",
    "    #get name from fips if fips specified\n",
    "    if county.isdigit():\n",
    "        lookup = fips.set_index('fips')['name']\n",
    "        county_fips = county\n",
    "        name = lookup[county_fips]\n",
    "    #get fips from name if name specified\n",
    "    else:\n",
    "        lookup = fips.set_index('name')['fips']\n",
    "        name = county\n",
    "        county_fips = lookup[name]\n",
    "    \n",
    "    \n",
    "    #get geodataframe of block group shapefile\n",
    "    bgfile_name = 'http://www2.census.gov/geo/tiger/GENZ2015/shp/cb_2015_{}_bg_500k.zip'.format(county_fips[:2])\n",
    "    bg_geo = zip_shp_to_gdf(bgfile_name)\n",
    "    \n",
    "    #subset to those that are in the county and project it to the CRS\n",
    "    bg_geo=bg_geo[bg_geo['GEOID'].str[:5]==county_fips].to_crs(epsg=epsg).set_index(\"GEOID\")['geometry']\n",
    "    \n",
    "    #specify variable list and variable names for the census api function\n",
    "    varlist = ['B03002_003E', \n",
    "               'B03002_012E',\n",
    "               'B03002_004E', \n",
    "               'B03002_006E',\n",
    "               'B03002_005E',\n",
    "               'B03002_007E',\n",
    "               'B03002_008E',\n",
    "               'B03002_009E']\n",
    "    names = ['White',\n",
    "             'Hispanic',\n",
    "             'Black',\n",
    "             'Asian',\n",
    "             'AI/AN',\n",
    "             'NH/PI',\n",
    "             'Other_',\n",
    "             'Two Plus']\n",
    "    \n",
    "    #read in block group level census variables\n",
    "    dems = get_census_variables(2015, 'acs5', 'block group', \n",
    "                                {'county':county_fips[2:], \n",
    "                                 'state':county_fips[:2]}, varlist, names)\n",
    "    #Calculate other as sum of those not in the 4 most populated race categories\n",
    "    dems['Other']=dems[['AI/AN', 'NH/PI','Other_', 'Two Plus']].sum(1)\n",
    "    \n",
    "    #Calculate county boundaries as the union of block groups \n",
    "    union = gpd.GeoSeries(bg_geo.unary_union)\n",
    "    \n",
    "    #if axes object is specified, plot to this axis, otherwise create a new one\n",
    "    if ax:\n",
    "        union.plot(color='white', figsize=figsize, ax=ax)\n",
    "    else:\n",
    "        ax = union.plot(color='white', figsize=figsize)\n",
    "   \n",
    "    #set aspect equal and add title if specified\n",
    "    ax.set(aspect='equal', xticks=[], yticks=[])\n",
    "    #set title as county name\n",
    "    ax.set_title(name, size=15)\n",
    "    \n",
    "    #annotate the dot per person ratio\n",
    "    ax.annotate(\"1 dot = {} people\".format(pts_per_person), \n",
    "                xy=(.5, .97), xycoords='axes fraction', horizontalalignment='center',\n",
    "                fontsize = 12)\n",
    "        \n",
    "    #loop each race category and generate points for each within each block group \n",
    "    list_of_point_categories=[]\n",
    "    for field in ['White','Hispanic','Black','Asian','Other']:           \n",
    "        ps=gpd.GeoDataFrame(gen_points_in_gdf_polys(geometry = bg_geo, values=dems[field],\n",
    "                             points_per_value = pts_per_person, seed=seed))\n",
    "        ps['field']=field\n",
    "        list_of_point_categories.append(ps)\n",
    "    all_points=gpd.GeoDataFrame(pd.concat(list_of_point_categories))\n",
    "    all_points.plot(ax=ax, markersize=2, alpha=dot_transparency, \n",
    "              column='field', categorical=True, legend=legend)\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'osr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-8562a836bb9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgen_count_dot_density_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Alameda County, CA'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpts_per_person\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-43-f42cb915a25e>\u001b[0m in \u001b[0;36mgen_count_dot_density_map\u001b[0;34m(county, pts_per_person, epsg, seed, dot_transparency, figsize, ax, legend)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;31m#get geodataframe of block group shapefile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mbgfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'http://www2.census.gov/geo/tiger/GENZ2015/shp/cb_2015_{}_bg_500k.zip'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounty_fips\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m     \u001b[0mbg_geo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip_shp_to_gdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbgfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;31m#subset to those that are in the county and project it to the CRS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-f42cb915a25e>\u001b[0m in \u001b[0;36mzip_shp_to_gdf\u001b[0;34m(zip_file_name)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mattributes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfield_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mproj4_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mosr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSpatialReference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExportToProj4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mgdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGeoDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeometry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeometry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproj4_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'osr' is not defined"
     ]
    }
   ],
   "source": [
    "gen_count_dot_density_map('Alameda County, CA', pts_per_person=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time= df['dwell_time'][df['dwell_time'] >= 14400000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work =df.groupby([\"venue_name\", time])[\"advertiser_id\"].count()\n",
    "work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df.groupby([\"venue_name\", time])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnan= nan.groupby(\"advertiser_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.datetime.fromtimestamp(1583143996)\n",
    "print(timestamp.strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
